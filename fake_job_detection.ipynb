{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TMudlJIywie",
        "outputId": "edc32172-e7ad-4a90-b6a9-15989b538989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model & tokenizer loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model(\"fake_job_model.keras\")\n",
        "\n",
        "# Load tokenizer\n",
        "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "print(\"Model & tokenizer loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# STEP 1: Required Libraries\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 2: Load Model & Tokenizer\n",
        "# -------------------------------\n",
        "fake_job_model = load_model(\"fake_job_model.keras\")\n",
        "\n",
        "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 3: Function to Predict Job Type\n",
        "# -------------------------------\n",
        "def predict_job(text):\n",
        "    # Convert text to sequence\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=100)  # Max length = 100, same as training\n",
        "    pred = fake_job_model.predict(padded)[0][0]\n",
        "\n",
        "    print(f\"Fake probability: {pred:.3f}\")\n",
        "    if pred >= 0.5:\n",
        "        print(\"FAKE JOB ğŸš¨\")\n",
        "    else:\n",
        "        print(\"REAL JOB âœ…\")\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 4: Example Usage\n",
        "# -------------------------------\n",
        "sample_text1 = \"Urgent hiring for online data entry work. Flexible hours, weekly payment guaranteed. Training will be provided. Registration fee of Rs. 199 required to activate account.\"\n",
        "sample_text2 = \"Looking for a Data Analyst with Python and SQL experience. Full-time role, apply online with CV.\"\n",
        "\n",
        "print(\"Sample 1:\")\n",
        "predict_job(sample_text1)\n",
        "print(\"\\nSample 2:\")\n",
        "predict_job(sample_text2)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 5 (Optional): Test on CSV File\n",
        "# -------------------------------\n",
        "# dataset_path = \"/content/fake_job_postings.csv\"  # Path to your CSV\n",
        "# df = pd.read_csv(dataset_path, on_bad_lines='skip')\n",
        "# df['prediction'] = df['description'].apply(lambda x: fake_job_model.predict(pad_sequences(tokenizer.texts_to_sequences([x]), maxlen=100))[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i8dIZ0YzdfO",
        "outputId": "bf49af1c-d475-4a20-b3f1-431cf5d03e8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
            "Fake probability: 0.957\n",
            "FAKE JOB ğŸš¨\n",
            "\n",
            "Sample 2:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Fake probability: 0.828\n",
            "FAKE JOB ğŸš¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LqNuW84wz-tu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}